{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P1",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Tm6uoROHz2sdn_DACXgPpx48t7hS7pN5",
      "authorship_tag": "ABX9TyOzoxku5kicJ5GAcEJiytgh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogdanjianu150/MaskRCNNv2/blob/main/P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMwZ1n5-sZH_"
      },
      "source": [
        "from google.colab import drive \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNORsGBzyWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f941258c-4f7d-47df-a8e0-09175751cf3d"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Olyj75E-JeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f57ebe2-0563-4420-b7ee-16480eabc8b2"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y\n",
        "\n",
        "!pip install tensorflow==1.15.0\n",
        "!pip install keras==2.2.5\n",
        "!pip install h5py==2.10.0\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 2.8.0\n",
            "Uninstalling keras-2.8.0:\n",
            "  Successfully uninstalled keras-2.8.0\n",
            "\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\n",
            "Found existing installation: Keras-Preprocessing 1.1.2\n",
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "Found existing installation: keras-vis 0.4.1\n",
            "Uninstalling keras-vis-0.4.1:\n",
            "  Successfully uninstalled keras-vis-0.4.1\n",
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Successfully uninstalled tensorflow-2.8.0\n",
            "Found existing installation: h5py 3.1.0\n",
            "Uninstalling h5py-3.1.0:\n",
            "  Successfully uninstalled h5py-3.1.0\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.44.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 787 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.5)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.13.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.6.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=552001681342714b5c88ba9502fe7f913f846accb2ac6c460ed2863ce18fda6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: h5py, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 h5py-3.6.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting keras==2.2.5\n",
            "  Downloading Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n",
            "\u001b[K     |████████████████████████████████| 336 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.5) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.5\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.6.0\n",
            "    Uninstalling h5py-3.6.0:\n",
            "      Successfully uninstalled h5py-3.6.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65I0_RvczNIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "b9826b28-4f5d-442d-9070-bed19576be54"
      },
      "source": [
        "pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.5 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FyTcU_K042h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a7ebb6-b446-4483-e5b0-940b53bd54dc"
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn.config import Config\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import model as modellib\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import visualize\n",
        "from drive.MyDrive.Mask_RCNN.mrcnn import utils\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXkTZ1N06OV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fa9d4d-fdd0-4c8a-af67-40f427345d28"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvyUG7wP0Yax"
      },
      "source": [
        "dataset_path = os.path.abspath(\"/content/drive/MyDrive/trashnet\")\n",
        "images_path = os.path.abspath(\"/content/drive/MyDrive/trashnet/dataset\")\n",
        "masks_path = os.path.sep.join([dataset_path, \"masks_modif.json\"])\n",
        "\n",
        "\n",
        "\n",
        "training_split = 0.75\n",
        "\n",
        "image_paths = sorted(list(paths.list_images(images_path)))\n",
        "idxs = list(range(0, len(image_paths) ))\n",
        "random.seed(42)\n",
        "random.shuffle(idxs)\n",
        "i = int(len(idxs) * training_split)\n",
        "train_idxs = idxs[:i]\n",
        "val_idxs = idxs[i:]\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffwsufpb4RO-"
      },
      "source": [
        "class_names = {1 : \"cardboard\", 2 : \"glass\", 3: \"paper\", 4: \"plastic\", 5: \"metal\", 6: \"trash\"}\n",
        "#class_names ={1: \"trash\"}\n",
        "\n",
        "coco_path = \"/content/drive/MyDrive/mask_rcnn_coco.h5\"\n",
        "\n",
        "LOGS_AND_MODEL_DIR = \"logs\"\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJn8fyG5B7W"
      },
      "source": [
        "class TrashConfig(Config):\n",
        "  NAME = \"trash\"\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "  STEPS_PER_EPOCH = len(train_idxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
        "  NUM_CLASSES = len(class_names) + 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psewri265nCe"
      },
      "source": [
        "class TrashInferenceConfig(TrashConfig):\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "  DETECTION_MIN_CONFIDENCE = 0.9\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-2iDAY-54iE"
      },
      "source": [
        "class TrashDataset(utils.Dataset):\n",
        "  def __init__(self, imagePaths, masksPath, classNames, width = 1024):\n",
        "    super().__init__(self)\n",
        "    self.imagePaths = imagePaths\n",
        "    self.classNames = classNames\n",
        "    self.width = width\n",
        "    self.annots = self.load_annotation_data(masksPath)\n",
        "\n",
        "  def load_annotation_data(self, masksPath):\n",
        "   annotations = json.loads(open(masksPath).read())\n",
        "   annots = {}\n",
        "\n",
        "   #for data in sorted(open(masksPath).read()):\n",
        "     #annots[data[\"filename\"]] = data\n",
        "\n",
        "   #return annots\n",
        "   return annotations\n",
        "\n",
        "  def load_trash(self, idxs):\n",
        "    for (class_id, label) in  self.classNames.items():\n",
        "      self.add_class(\"cardboard\", class_id, label)\n",
        "      self.add_class(\"glass\", class_id, label)\n",
        "      self.add_class(\"paper\", class_id, label)\n",
        "      self.add_class(\"plastic\", class_id, label)\n",
        "      self.add_class(\"metal\", class_id, label)\n",
        "      self.add_class(\"trash\", class_id, label)\n",
        "\n",
        "\n",
        "    \n",
        "    image_path = os.listdir(self.imagePaths)\n",
        "    for i in idxs:\n",
        "      \n",
        "      #image_path = self.imagePaths[i]\n",
        "      #filename = image_path[i].split(os.path.sep)[-1]\n",
        "      \n",
        "      \n",
        "      k = self.imagePaths + '/' + str(i)\n",
        "      filename = k.split(os.path.sep)[-1]\n",
        "      image = cv2.imread(k)\n",
        "      #(origH, origW) = image.shape[:2]\n",
        "      #image = imutils.resize(image, width = self.width)\n",
        "      #(newH, newW) = image.shape[:2]\n",
        "      self.add_image(\"trash\", image_id = i, #width = newW, height = newH,\n",
        "                     #orig_width = origW, orig_height=origH,\n",
        "                     path = k)\n",
        "  \n",
        "  def load_image(self, image_id):\n",
        "   p = self.image_info[image_id][\"path\"]\n",
        "   image = cv2.imread(p)\n",
        "   #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "   #image = imutils.resize(image, width = self.width)\n",
        "   return image\n",
        "\n",
        "  def load_mask(self, image_id):\n",
        "   info = self.image_info[image_id]\n",
        "   annot = self.annots[info[\"id\"]]\n",
        "\n",
        "   masks = np.zeros((info[\"height\"], info[\"width\"], len(annot[\"regions\"])), dtype = \"uint8\")\n",
        "\n",
        "   for (i, region) in enumerate(annot[\"regions\"]) :\n",
        "    region_mask = np.zeros(masks.shape[:2], dtype = \"uint8\")\n",
        "    sa = region[\"shape_attributes\"]\n",
        "    ra = region[\"region_attributes\"]\n",
        "    ratio = info[\"width\"] / float(info[\"orig_width\"])\n",
        "    cX = int(sa[\"cx\"] * ratio)\n",
        "    cY = int(sa[\"cy\"] * ratio)\n",
        "    r = int(sa[\"r\"] * ratio)\n",
        "\n",
        "    \n",
        "\n",
        "    cv2.circle(region_mask, (cX, cY), r, 1, -1)\n",
        "    \n",
        "    masks[:, :, i] = region_mask\n",
        "\n",
        "   return (masks.astype(\"bool\"), np.ones((masks.shape[-1], ), dtype =\"int32\"))\n",
        "\n",
        "      "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BJhorP-UVUxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP2MvoqceLEP"
      },
      "source": [
        "train_dataset = TrashDataset(images_path, masks_path, class_names)\n",
        "train_dataset.load_trash(train_idxs)\n",
        "train_dataset.prepare()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlVSx34KeQfO"
      },
      "source": [
        "val_dataset = TrashDataset(images_path, masks_path, class_names)\n",
        "val_dataset.load_trash(val_idxs)\n",
        "val_dataset.prepare()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX5Grp0ReUtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da07af44-7362-4454-edbf-e97d6bb88a17"
      },
      "source": [
        "config = TrashConfig()\n",
        "config.display()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                19\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           trash\n",
            "NUM_CLASSES                    7\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1890\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K61KQloleeGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "683f9f79-633c-4f1c-dfe1-89a09a0d392f"
      },
      "source": [
        "model = modellib.MaskRCNN(mode = \"training\", config = config, model_dir = LOGS_AND_MODEL_DIR)\n",
        "model.load_weights(coco_path, by_name = True, exclude = [\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_dataset, val_dataset, epochs = 20, layers = \"heads\", learning_rate = config.LEARNING_RATE)\n",
        "model.train(train_dataset, val_dataset, epochs = 40, layers = \"all\", learning_rate = config.LEARNING_RATE / 10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: logs/trash20220317T1243/mask_rcnn_trash_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error processing image {'id': 2029, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2029'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2029\n",
            "ERROR:root:Error processing image {'id': 2029, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2029'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2029\n",
            "ERROR:root:Error processing image {'id': 41, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/41'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 41\n",
            "ERROR:root:Error processing image {'id': 41, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/41'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 41\n",
            "ERROR:root:Error processing image {'id': 1482, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1482'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1482\n",
            "ERROR:root:Error processing image {'id': 2095, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2095'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2095\n",
            "ERROR:root:Error processing image {'id': 1482, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1482'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1482\n",
            "ERROR:root:Error processing image {'id': 810, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/810'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 810\n",
            "ERROR:root:Error processing image {'id': 2095, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2095'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2095\n",
            "ERROR:root:Error processing image {'id': 2479, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2479'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2479\n",
            "ERROR:root:Error processing image {'id': 810, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/810'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 810\n",
            "ERROR:root:Error processing image {'id': 2479, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2479'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2479\n",
            "ERROR:root:Error processing image {'id': 1432, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1432'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1432\n",
            "ERROR:root:Error processing image {'id': 153, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/153'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 153\n",
            "ERROR:root:Error processing image {'id': 153, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/153'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 153\n",
            "ERROR:root:Error processing image {'id': 1432, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1432'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1432\n",
            "ERROR:root:Error processing image {'id': 1970, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1970'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1970\n",
            "ERROR:root:Error processing image {'id': 1360, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1360'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1360\n",
            "ERROR:root:Error processing image {'id': 1970, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1970'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1970\n",
            "ERROR:root:Error processing image {'id': 1360, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/1360'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 1360\n",
            "ERROR:root:Error processing image {'id': 2364, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2364'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2364\n",
            "ERROR:root:Error processing image {'id': 2364, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/2364'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 2364\n",
            "ERROR:root:Error processing image {'id': 308, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/308'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 308\n",
            "ERROR:root:Error processing image {'id': 308, 'source': 'trash', 'path': '/content/drive/MyDrive/trashnet/dataset/308'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n",
            "    annot = self.annots[info[\"id\"]]\n",
            "KeyError: 308\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 641, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1709, in data_generator\n    use_mini_mask=config.USE_MINI_MASK)\n  File \"/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\", line 1212, in load_image_gt\n    mask, class_ids = dataset.load_mask(image_id)\n  File \"<ipython-input-29-14938efec25e>\", line 56, in load_mask\n    annot = self.annots[info[\"id\"]]\nKeyError: 1970\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-db4358731274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mrcnn_class_logits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrcnn_bbox_fc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrcnn_bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mrcnn_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"heads\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1707\u001b[0m                     load_image_gt(dataset, config, image_id, augment=augment,\n\u001b[1;32m   1708\u001b[0m                                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m                                 use_mini_mask=config.USE_MINI_MASK)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;31m# Skip images that have no instances. This can happen in cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Mask_RCNN/mrcnn/model.py\u001b[0m in \u001b[0;36mload_image_gt\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;31m# Load image and mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m     \u001b[0moriginal_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     image, window, scale, padding, crop = utils.resize_image(\n",
            "\u001b[0;32m<ipython-input-29-14938efec25e>\u001b[0m in \u001b[0;36mload_mask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m    \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m    \u001b[0mannot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m    \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"regions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1970"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIyYdKDsDCym"
      },
      "source": [
        "config = TrashInferenceConfig()\n",
        "model = modellib.MaskRCNN(mode = \"inference\", config = config, model_dir = logs_and_model_dir)\n",
        "\n",
        "weights = model.find_last()\n",
        "model.load_weigths(weights, by_name = True )\n",
        "\n",
        "\n",
        "image = cv2.imread(args[\"image\"])\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = imutils.resize(image, width = 1024)\n",
        "\n",
        "r = model.detect([image], verbose = 1)[0]\n",
        "\n",
        "for i in range(0, r[\"rois\"].shape[0]):\n",
        "  mask = r[\"masks\"][:, :, i]\n",
        "  image = visualize.apply_mask(image, mask, (1.0, 0.0, 0.0), alpha = 0.5)\n",
        "  image = visualize.draw_box(image, r[\"rois\"][i], [1.0, 0.0, 0.0])\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  for i in range(0, len(r[\"scores\"])):\n",
        "   (startY, startX, endY, endX) = r[\"rois\"][i]\n",
        "   class_id = r[\"class_ids\"][i]\n",
        "   label = class_names[class_id]\n",
        "   score = r[\"scores\"][i]\n",
        "\n",
        "   text = \"{}: {:.4f}\".format(label, score)\n",
        "   y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "   cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "      \n",
        "image = imutils.resize(image, width = 512)\n",
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}